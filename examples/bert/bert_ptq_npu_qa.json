{
  "input_model": {
    "type": "PyTorchModel",
    "model_loader": "load_bert_qa_model",
    "model_script": "user_model.py",
    "model_path": "google-bert/bert-large-uncased-whole-word-masking-finetuned-squad",
    "io_config": {
      "input_names": ["attention_mask", "inputs_embeds"],
      "input_shapes": [
        [1, 1, 512, 512],
        [1, 512, 1024]
      ],
      "input_types": ["float32", "float32"],
      "output_names": ["start_logits", "end_logits"],
      "output_shapes": [
        [1, 512],
        [1, 512]
      ]
    }
  },
  "engine": {
    "host": "host_system",
    "target": "target_system",
    "cache_dir": "temp/cache",
    "clean_cache": true,
    "clean_evaluation_cache": true,
    "evaluator": "squad_evaluator",
    "evaluate_input_model": false,
    "output_dir": "outputs/google/bert_large_uncased_qa"
  },
  "systems": {
    "host_system": {
      "type": "LocalSystem",
      "accelerators": [
        { "device": "cpu", "execution_providers": ["CPUExecutionProvider"] }
      ]
    },
    "target_system": {
      "type": "LocalSystem",
      "accelerators": [
        { "device": "npu", "execution_providers": ["QNNExecutionProvider"] }
      ]
    }
  },
  "data_configs": [
    {
      "name": "calibration_data",
      "type": "HuggingfaceContainer",
      "user_script": "user_data.py",
      "load_dataset_config": {
        "data_name": "squad",
        "split": "train"
      },
      "pre_process_data_config": {
        "type": "bert_pre_process_fast",
        "input_cols": ["question", "context"],
        "seq_length": 512,
        "max_samples": 10,
        "model_name": "google-bert/bert-large-uncased-whole-word-masking-finetuned-squad",
        "trust_remote_code": "true"
      },
      "dataloader_config": { "batch_size": 1 }
    },
    {
      "name": "eval_data",
      "type": "HuggingfaceContainer",
      "user_script": "user_data.py",
      "load_dataset_config": {
        "data_name": "squad",
        "split": "validation"
      },
      "pre_process_data_config": {
        "type": "bert_pre_process_fast",
        "input_cols": ["question", "context"],
        "seq_length": 512,
        "max_samples": 1000,
        "model_name": "google-bert/bert-large-uncased-whole-word-masking-finetuned-squad",
        "trust_remote_code": "true"
      },
      "post_process_data_config": {
        "type": "bert_qa_post_process"
      },
      "dataloader_config": { "batch_size": 1 }
    }
  ],
  "evaluators": {
    "squad_evaluator": {
      "metrics": [
        {
          "name": "eval_squad",
          "type": "custom",
          "data_config": "eval_data",
          "sub_types": [
            {
              "name": "exact_match",
              "priority": 1,
              "higher_is_better": true
            },
            { "name": "f1", "higher_is_better": true }
          ],
          "user_config": {
            "user_script": "user_eval.py",
            "metric_func": "eval_squad",
            "metric_func_kwargs": {
              "model_name": "google-bert/bert-large-uncased-whole-word-masking-finetuned-squad",
              "dataset_config": {
                "data_name": "squad",
                "split": "validation"
              },
              "seq_length": 512
            },
            "inference_settings": {
              "onnx": {
                "execution_provider": "QNNExecutionProvider",
                "session_options": {
                  "extra_session_config": {
                    "session.disable_cpu_ep_fallback": "1"
                  }
                },
                "provider_options": [
                  {
                    "htp_graph_finalization_optimization_mode": 3,
                    "htp_performance_mode": "burst"
                  }
                ]
              }
            }
          }
        }
      ]
    }
  },
  "passes": {
    "conversion": {
      "device": "cpu",
      "type": "OnnxConversion",
      "target_opset": 17,
      "dynamic": true,
      "use_dynamo_exporter": false,
      "save_as_external_data": true,
      "all_tensors_to_one_file": true
    },
    "qnn_preprocess": {
      "type": "QNNPreprocess",
      "fuse_layernorm": true,
      "save_as_external_data": true,
      "all_tensors_to_one_file": true
    },
    "quantization": {
      "type": "OnnxStaticQuantization",
      "data_config": "calibration_data",
      "quant_preprocess": true,
      "activation_type": "QUInt16",
      "weight_type": "QUInt8",
      "save_as_external_data": true,
      "all_tensors_to_one_file": true
    }
  }
}
